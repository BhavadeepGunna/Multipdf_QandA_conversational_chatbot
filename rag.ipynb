{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings,ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough,RunnableParallel\n",
    "from langchain_core.prompts import ChatPromptTemplate,PromptTemplate,MessagesPlaceholder\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain,create_history_aware_retriever\n",
    "from langchain_core.messages import HumanMessage\n",
    "from PyPDF2 import PdfReader\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(openai_api_key=os.getenv('OPENAI_API_KEY'),model=\"gpt-3.5-turbo\")\n",
    "embeddings=OpenAIEmbeddings(openai_api_key=os.getenv('OPENAI_API_KEY'))\n",
    "store={}\n",
    "def get_and_convert_pdf(input_pdf):\n",
    "    bytes_data = input_pdf.read()\n",
    "    with NamedTemporaryFile(delete=False) as tmp: \n",
    "        tmp.write(bytes_data)                      \n",
    "        data = PyPDFLoader(tmp.name).load_and_split()\n",
    "    os.remove(tmp.name)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    split= text_splitter.split_documents(docs)\n",
    "    return split\n",
    "    #for page in pages:\n",
    "    #    text+=page.extract_text(page)\n",
    "    #return text\n",
    "\n",
    "def create_Vectorstore(chunks):\n",
    "    \n",
    "    vectorstore=FAISS.from_documents(chunks,embeddings)\n",
    "    vectorstore.save_local('faiss_index')\n",
    "\n",
    "\n",
    "def get_rag_chain(vectorstore):\n",
    "\n",
    "    contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "    which might reference context in the chat history, formulate a standalone question \\\n",
    "    which can be understood without the chat history. Do NOT answer the question, \\\n",
    "    just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "    retriever=vectorstore.as_retriever()\n",
    "    contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", contextualize_q_system_prompt),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    history_aware_retriever = create_history_aware_retriever(\n",
    "        llm, retriever, contextualize_q_prompt\n",
    "    )\n",
    "\n",
    "    qa_system_prompt=\"\"\"\n",
    "    you are the assistant for question and answering tasks. use the following given retrieved context to answer the question.if you dont know the \n",
    "    answer just say that you don't know. give answer simply in three lines.\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    qa_prompt=ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            ('system',qa_system_prompt),\n",
    "            MessagesPlaceholder('chat_history'),\n",
    "            ('human',\"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    question_answer_chain=create_stuff_documents_chain(llm,qa_prompt)\n",
    "\n",
    "    rag_chain=create_retrieval_chain(history_aware_retriever,question_answer_chain)\n",
    "\n",
    "    return rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conversation_rag_chain(vectorstore):\n",
    "    rag_chain=get_rag_chain(vectorstore)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "        if session_id not in store:\n",
    "            print('0')\n",
    "            store[session_id] = ChatMessageHistory()\n",
    "        print('1')\n",
    "        return store[session_id]\n",
    "\n",
    "    conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    "    )\n",
    "\n",
    "    return conversational_rag_chain\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hyperparameter tuning is the process of selecting the best set of hyperparameters for a machine learning algorithm. Hyperparameters are parameters that are not learned during training and must be set before the learning process begins. Tuning these hyperparameters involves finding the optimal values to improve the model's performance.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = FAISS.load_local(\"faiss_index\",embeddings,allow_dangerous_deserialization=True)\n",
    "conversational_rag_chain=create_conversation_rag_chain(database)\n",
    "session_id=\"abc123\"\n",
    "user_question=\"what is hyperparameter tuning\"\n",
    "get_response(user_question,conversational_rag_chain,session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Common ways of hyperparameter tuning include techniques like Grid Search, Random Search, Bayesian Optimization, and more recently, techniques like Genetic Algorithms and Neural Architecture Search. These methods help in systematically exploring the hyperparameter space to find the best configuration for a machine learning model.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = FAISS.load_local(\"faiss_index\",embeddings,allow_dangerous_deserialization=True)\n",
    "conversational_rag_chain=create_conversation_rag_chain(database)\n",
    "session_id=\"abc123\"\n",
    "user_question=\"what are common ways of doing it\"\n",
    "get_response(user_question,conversational_rag_chain,session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[HumanMessage(content='what is hyperparameter tuning'), AIMessage(content='Hyperparameter tuning is the process of selecting the best set of hyperparameters for a machine learning algorithm. Hyperparameters are parameters that are set before the learning process begins, and tuning them involves finding the optimal values to improve the performance of the model. Techniques like grid search, random search, and Bayesian optimization are commonly used for hyperparameter tuning.'), HumanMessage(content='what are common ways of doing it'), AIMessage(content='Common ways of hyperparameter tuning include:\\n1. Grid Search: Exhaustively searching through a manually specified subset of hyperparameters to find the best combination.\\n2. Random Search: Randomly sampling hyperparameter combinations for evaluation.\\n3. Bayesian Optimization: Using probabilistic models to predict the performance of different hyperparameter configurations and selecting the most promising ones for evaluation.'), HumanMessage(content='what is hyperparameter tuning'), AIMessage(content=\"Hyperparameter tuning is the process of selecting the best set of hyperparameters for a machine learning algorithm. Hyperparameters are parameters that are not learned during training and must be set before the learning process begins. Tuning these hyperparameters involves finding the optimal values to improve the model's performance.\"), HumanMessage(content='what are common ways of doing it'), AIMessage(content='Common ways of hyperparameter tuning include techniques like Grid Search, Random Search, Bayesian Optimization, and more recently, techniques like Genetic Algorithms and Neural Architecture Search. These methods help in systematically exploring the hyperparameter space to find the best configuration for a machine learning model.')])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store['abc123']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 17:54:02.948 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\user\\Desktop\\langchain\\RAG ChatBot\\venv\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    st.set_page_config(\"Chat with multiple PDFS\")\n",
    "    st.header(\"Chat with PDF using OpenAI\")\n",
    "    preprocess()\n",
    "    database = FAISS.load_local(\"faiss_index\",embeddings,allow_dangerous_deserialization=True)\n",
    "    conversational_rag_chain=create_conversation_rag_chain(database)\n",
    "    session_id=\"abc123\"\n",
    "    user_question = st.text_input(\"Ask question related to the given context\")\n",
    "    if user_question:\n",
    "        submit=st.button('submit')\n",
    "        if submit:\n",
    "            with st.spinner(\"processing...\"):\n",
    "                st.write(get_response(user_question,conversational_rag_chain,session_id))\n",
    "                st.success(\"done\")\n",
    "            \n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (0.0.34)\n",
      "Requirement already satisfied: streamlit in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (1.33.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from langchain-community) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from langchain-community) (0.6.4)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.45 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from langchain-community) (0.1.45)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from langchain-community) (0.1.49)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from streamlit) (5.3.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from streamlit) (1.7.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: packaging<25,>=16.8 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from streamlit) (10.3.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from streamlit) (4.25.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from streamlit) (15.0.2)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from streamlit) (4.11.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from streamlit) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from streamlit) (6.4)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from streamlit) (4.0.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.21.1)\n",
      "Requirement already satisfied: toolz in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.45->langchain-community) (1.33)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.45->langchain-community) (2.7.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.17.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.45->langchain-community) (2.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.45->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.45->langchain-community) (2.18.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\desktop\\langchain\\rag chatbot\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-community streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'st.session_state has no key \"chat_history\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\langchain\\RAG ChatBot\\venv\\lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:408\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\langchain\\RAG ChatBot\\venv\\lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:453\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[1;34m(self, widget_id, user_key)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m st\u001b[38;5;241m.\u001b[39msession_state:\n\u001b[0;32m      6\u001b[0m     st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 7\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mStreamlitChatMessageHistory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchat_history\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m history\u001b[38;5;241m.\u001b[39madd_user_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhi!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m history\u001b[38;5;241m.\u001b[39madd_ai_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhats up?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\langchain\\RAG ChatBot\\venv\\lib\\site-packages\\langchain_community\\chat_message_histories\\streamlit.py:25\u001b[0m, in \u001b[0;36mStreamlitChatMessageHistory.__init__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m st\u001b[38;5;241m.\u001b[39msession_state:\n\u001b[0;32m     24\u001b[0m     st\u001b[38;5;241m.\u001b[39msession_state[key] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_messages \u001b[38;5;241m=\u001b[39m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key \u001b[38;5;241m=\u001b[39m key\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\langchain\\RAG ChatBot\\venv\\lib\\site-packages\\streamlit\\runtime\\state\\session_state_proxy.py:90\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     88\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(key)\n\u001b[0;32m     89\u001b[0m require_valid_user_key(key)\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_session_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\langchain\\RAG ChatBot\\venv\\lib\\site-packages\\streamlit\\runtime\\state\\safe_session_state.py:93\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_yield_callback()\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\langchain\\RAG ChatBot\\venv\\lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:410\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(widget_id, key)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'st.session_state has no key \"chat_history\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization'"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from langchain_community.chat_message_histories import (\n",
    "    StreamlitChatMessageHistory,\n",
    ")\n",
    "if 'chat_history' not in st.session_state:\n",
    "    st.session_state['chat_history'] = []\n",
    "history = StreamlitChatMessageHistory(key='chat_history')\n",
    "\n",
    "history.add_user_message(\"hi!\")\n",
    "history.add_ai_message(\"whats up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'st.session_state has no key \"chat_history\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\langchain\\RAG ChatBot\\venv\\lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:408\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\langchain\\RAG ChatBot\\venv\\lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:453\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[1;34m(self, widget_id, user_key)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Now import and use StreamlitChatMessageHistory\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_message_histories\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StreamlitChatMessageHistory\n\u001b[1;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mStreamlitChatMessageHistory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchat_history\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m history\u001b[38;5;241m.\u001b[39madd_user_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhi!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m history\u001b[38;5;241m.\u001b[39madd_ai_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhats up?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\langchain\\RAG ChatBot\\venv\\lib\\site-packages\\langchain_community\\chat_message_histories\\streamlit.py:25\u001b[0m, in \u001b[0;36mStreamlitChatMessageHistory.__init__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m st\u001b[38;5;241m.\u001b[39msession_state:\n\u001b[0;32m     24\u001b[0m     st\u001b[38;5;241m.\u001b[39msession_state[key] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_messages \u001b[38;5;241m=\u001b[39m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key \u001b[38;5;241m=\u001b[39m key\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\langchain\\RAG ChatBot\\venv\\lib\\site-packages\\streamlit\\runtime\\state\\session_state_proxy.py:90\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     88\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(key)\n\u001b[0;32m     89\u001b[0m require_valid_user_key(key)\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_session_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\langchain\\RAG ChatBot\\venv\\lib\\site-packages\\streamlit\\runtime\\state\\safe_session_state.py:93\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_yield_callback()\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\langchain\\RAG ChatBot\\venv\\lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:410\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(widget_id, key)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'st.session_state has no key \"chat_history\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization'"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "# Now import and use StreamlitChatMessageHistory\n",
    "from langchain_community.chat_message_histories import StreamlitChatMessageHistory\n",
    "\n",
    "history = StreamlitChatMessageHistory(key='chat_history')\n",
    "\n",
    "history.add_user_message(\"hi!\")\n",
    "history.add_ai_message(\"whats up?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
